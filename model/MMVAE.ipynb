{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data\n",
    "from scipy import misc\n",
    "from torch import optim\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm, trange\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
    "from transformers import AutoTokenizer, BertTokenizer, BertModel, BertForSequenceClassification\n",
    "from collections import namedtuple\n",
    "import torchvision.models as models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from laserembeddings import Laser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable gpu device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 8888\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('../', 'data', 'TRAINING','images')\n",
    "trial_dir = os.path.join('../', 'data', 'Users', 'fersiniel', 'Desktop', 'MAMI - TO LABEL/TRIAL DATASET', 'images')\n",
    "\n",
    "# load training label\n",
    "train_df = pd.read_csv('../data/TRAINING/training.csv', sep='\\t')\n",
    "# load trial label\n",
    "trial_df = pd.read_csv('../data/Users/fersiniel/Desktop/MAMI - TO LABEL/TRIAL DATASET/trial.csv', sep='\\t')\n",
    "# load test label\n",
    "test_df = pd.read_csv('../data/test/Test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.127400</td>\n",
       "      <td>0.28100</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.095300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500025</td>\n",
       "      <td>0.333437</td>\n",
       "      <td>0.44951</td>\n",
       "      <td>0.414402</td>\n",
       "      <td>0.293644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         misogynous       shaming   stereotype  objectification      violence\n",
       "count  10000.000000  10000.000000  10000.00000     10000.000000  10000.000000\n",
       "mean       0.500000      0.127400      0.28100         0.220200      0.095300\n",
       "std        0.500025      0.333437      0.44951         0.414402      0.293644\n",
       "min        0.000000      0.000000      0.00000         0.000000      0.000000\n",
       "25%        0.000000      0.000000      0.00000         0.000000      0.000000\n",
       "50%        0.500000      0.000000      0.00000         0.000000      0.000000\n",
       "75%        1.000000      0.000000      1.00000         0.000000      0.000000\n",
       "max        1.000000      1.000000      1.00000         1.000000      1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "      <th>Text Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Milk Milk.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BREAKING NEWS: Russia releases photo of DONALD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MAN SEEKING WOMAN Ignad 18 O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Me explaining the deep lore of. J.R.R. Tolkein...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  misogynous  shaming  stereotype  objectification  violence  \\\n",
       "0      1.jpg           0        0           0                0         0   \n",
       "1     10.jpg           1        0           0                0         1   \n",
       "2   1000.jpg           0        0           0                0         0   \n",
       "3  10000.jpg           0        0           0                0         0   \n",
       "4  10006.jpg           0        0           0                0         0   \n",
       "\n",
       "                                  Text Transcription  \n",
       "0                                      Milk Milk.zip  \n",
       "1  ROSES ARE RED, VIOLETS ARE BLUE IF YOU DON'T S...  \n",
       "2  BREAKING NEWS: Russia releases photo of DONALD...  \n",
       "3                       MAN SEEKING WOMAN Ignad 18 O  \n",
       "4  Me explaining the deep lore of. J.R.R. Tolkein...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define image transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_size = 128\n",
    "# pretrained_size = 256\n",
    "pretrained_size = 224\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds= [0.229, 0.224, 0.225]\n",
    "\n",
    "# train_transforms = transforms.Compose([\n",
    "#                            transforms.Resize(pretrained_size),\n",
    "#                            transforms.RandomRotation(5),\n",
    "#                            transforms.RandomHorizontalFlip(0.5),\n",
    "#                            transforms.RandomCrop(pretrained_size, padding = 10),\n",
    "#                            transforms.ToTensor(),\n",
    "#                            transforms.Normalize(mean = pretrained_means, \n",
    "#                                                 std = pretrained_stds)\n",
    "#                        ])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ])\n",
    "\n",
    "# trial_transforms = transforms.Compose([\n",
    "#                            transforms.Resize(pretrained_size),\n",
    "#                            transforms.CenterCrop(pretrained_size),\n",
    "#                            transforms.ToTensor(),\n",
    "#                            transforms.Normalize(mean = pretrained_means, \n",
    "#                                                 std = pretrained_stds)\n",
    "#                        ])\n",
    "\n",
    "trial_transforms = train_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip pretrained model for image encoding\n",
    "\n",
    "clip_pretrained = SentenceTransformer('clip-ViT-B-32')\n",
    "\n",
    "# Laser model for text encoding\n",
    "\n",
    "laser_model = Laser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-define Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAMIDataset(Dataset):\n",
    "    \"\"\"MAMI dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file, sep='\\t')\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.df.iloc[idx, 0])\n",
    "        meme = Image.open(img_name)#.convert(\"RGB\")   # convert to RGB is important\n",
    "        meme = torch.Tensor(clip_pretrained.encode(meme))\n",
    "        labels = self.df.iloc[idx, 1:-1]   # multi-labels\n",
    "        labels = np.array(labels)\n",
    "        labels = labels.astype('long')\n",
    "        \n",
    "        text = self.df.iloc[idx, -1]   # Text transcription\n",
    "        text = torch.Tensor(laser_model.embed_sentences(text, lang='en'))\n",
    "#         text = \"[CLS] \" + text + \" [SEP]\"   # Add special tokens\n",
    "        \n",
    "#         tokenized_text = tokenizer.tokenize(text)\n",
    "#         # Map the token strings to their vocabulary indeces.\n",
    "#         indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#         segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "#         tokens_tensor = torch.tensor([indexed_tokens])\n",
    "#         segments_tensor = torch.tensor([segments_ids])\n",
    "\n",
    "#         text_ids = tokenizer(text, return_tensors=\"pt\", padding='max_length', max_length=512, truncation=True)\n",
    "        \n",
    "        sample = {'meme': meme, 'labels': labels, 'text': text}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['meme'] = self.transform(meme)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAMITestset(Dataset):\n",
    "    \"\"\"MAMI dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file, sep='\\t')\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.df.iloc[idx, 0])\n",
    "        meme = Image.open(img_name)#.convert(\"RGB\")   # convert to RGB is important\n",
    "        meme = torch.Tensor(clip_pretrained.encode(meme))\n",
    "        \n",
    "        text = self.df.iloc[idx, -1]   # Text transcription\n",
    "        text = torch.Tensor(laser_model.embed_sentences(text, lang='en'))\n",
    "        \n",
    "#         text = \"[CLS] \" + text + \" [SEP]\"   # Add special tokens\n",
    "        \n",
    "#         tokenized_text = tokenizer.tokenize(text)\n",
    "#         # Map the token strings to their vocabulary indeces.\n",
    "#         indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#         segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "#         tokens_tensor = torch.tensor([indexed_tokens])\n",
    "#         segments_tensor = torch.tensor([segments_ids])\n",
    "        \n",
    "        sample = {'meme': meme, 'text': text}\n",
    "\n",
    "        if self.transform:\n",
    "            sample['meme'] = self.transform(meme)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the train and trial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_root_dir = '../data/Users/fersiniel/Desktop/MAMI - TO LABEL/TRIAL DATASET/'\n",
    "# trial_data = MAMIDataset(trial_root_dir + 'trial.csv', trial_root_dir, trial_transforms)\n",
    "trial_data = MAMIDataset(trial_root_dir + 'trial.csv', trial_root_dir)\n",
    "\n",
    "train_root_dir = '../data/TRAINING/'\n",
    "# train_data = MAMIDataset(train_root_dir + 'training.csv', train_root_dir, train_transforms)\n",
    "train_data = MAMIDataset(train_root_dir + 'training.csv', train_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_root_dir = '../data/test/'\n",
    "# train_data = MAMIDataset(train_root_dir + 'training.csv', train_root_dir, train_transforms)\n",
    "test_data = MAMITestset(test_root_dir + 'Test.csv', test_root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data, \n",
    "                                           [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = copy.deepcopy(valid_data)\n",
    "# valid_data.dataset.transform = trial_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 9000\n",
      "Number of validation examples: 1000\n",
      "Number of testing examples: 100\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(trial_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create batch iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = data.DataLoader(train_data, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "trial_iterator = data.DataLoader(trial_data, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct VAE class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, zsize, output_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.zsize = zsize\n",
    "        self.fc1 = nn.Linear(zsize, zsize)   # 4 * 4 is the current size of the image\n",
    "        self.fc2 = nn.Linear(zsize, zsize)\n",
    "\n",
    "        ######\n",
    "        # multi-tasks sub-networks\n",
    "        self.fc_misogynous = nn.Linear(zsize, output_dim)\n",
    "        self.fc_shaming = nn.Linear(zsize, output_dim)\n",
    "        self.fc_stereotype = nn.Linear(zsize, output_dim)\n",
    "        self.fc_objectification = nn.Linear(zsize, output_dim)\n",
    "        self.fc_violence = nn.Linear(zsize, output_dim)\n",
    "        \n",
    "        \n",
    "        # encoder layers\n",
    "        self.enc_txt_fc = nn.Linear(1024, int(0.5 * zsize))\n",
    "        self.enc_img_fc1 = nn.Linear(512, int(0.5 * zsize))\n",
    "#         self.enc_img_fc2 = nn.Linear(1024, int(0.5 * zsize))\n",
    "        \n",
    "        # decoder layers\n",
    "        self.dec_txt_fc = nn.Linear(zsize, 1024)\n",
    "        self.dec_img_fc1 = nn.Linear(zsize, 512)\n",
    "#         self.dec_img_fc2 = nn.Linear(1024, 2048)\n",
    "\n",
    "        # batch normalizations\n",
    "        self.enc_txt_bn = nn.BatchNorm1d(num_features=int(0.5 * zsize))\n",
    "        self.enc_img_bn1 = nn.BatchNorm1d(num_features=int(0.5 * zsize))\n",
    "#         self.enc_img_bn2 = nn.BatchNorm1d(num_features=int(0.5 * zsize))\n",
    "        \n",
    "        self.dec_txt_bn = nn.BatchNorm1d(num_features=1024)\n",
    "        self.dec_img_bn1 = nn.BatchNorm1d(num_features=512)\n",
    "#         self.dec_img_bn2 = nn.BatchNorm1d(num_features=2048)\n",
    "        \n",
    "        # dropout\n",
    "        self.dropout_txt_enc = nn.Dropout(0.2)\n",
    "        self.dropout_img_enc = nn.Dropout(0.2)\n",
    "        self.dropout_txt_dec = nn.Dropout(0.2)\n",
    "        self.dropout_img_dec = nn.Dropout(0.2)\n",
    "        \n",
    "        \n",
    "    def img_encode(self, x_img):\n",
    "#         _, x_img = self.resnet_pretrained(x_img)\n",
    "        x_img = F.relu(self.dropout_img_enc(self.enc_img_bn1(self.enc_img_fc1(x_img))))\n",
    "#         x_img = F.relu(self.enc_img_fc2(x_img))\n",
    "        \n",
    "        return x_img   # [bs, 2048]\n",
    "\n",
    "    def txt_encode(self, x_txt):\n",
    "\n",
    "        x_txt = x_txt.view(x_txt.shape[0], 1024)\n",
    "        x_txt = F.relu(self.dropout_txt_enc(self.enc_txt_bn(self.enc_txt_fc(x_txt))))\n",
    "        return x_txt   # [bs, 0.5 * zsize]\n",
    "\n",
    "    def encode(self, x_img, x_txt):\n",
    "        \n",
    "        x_img = self.img_encode(x_img)\n",
    "        \n",
    "        x_txt = self.txt_encode(x_txt)\n",
    "        \n",
    "        # concate x_img and x_txt\n",
    "        x = torch.cat((x_txt, x_img), 1)\n",
    "        \n",
    "        h1 = self.fc1(x)   # mu\n",
    "        h2 = self.fc2(x)   # logvar\n",
    "        return h1, h2\n",
    "    \n",
    "    def subtask_misogynous(self, z):\n",
    "        \n",
    "        h = self.fc_misogynous(z)\n",
    "        return h\n",
    "    \n",
    "    def subtask_shaming(self, z):\n",
    "        \n",
    "        h = self.fc_shaming(z)\n",
    "        return h\n",
    "    \n",
    "    def subtask_stereotype(self, z):\n",
    "\n",
    "        h = self.fc_stereotype(z)\n",
    "        return h\n",
    "    \n",
    "    def subtask_objectification(self, z):\n",
    "\n",
    "        h = self.fc_objectification(z)\n",
    "        return h\n",
    "    \n",
    "    def subtask_violence(self, z):\n",
    "\n",
    "        h = self.fc_violence(z)\n",
    "        return h\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, x):\n",
    "#         x = x.view(x.shape[0], self.zsize)   # flatten\n",
    "\n",
    "        # Decoding txt\n",
    "        dec_x_txt = F.relu(self.dropout_txt_dec(self.dec_txt_bn(self.dec_txt_fc(x))))\n",
    "        \n",
    "        # Decoding img\n",
    "        dec_x_img = F.relu(self.dropout_img_dec(self.dec_img_bn1(self.dec_img_fc1(x))))\n",
    "#         dec_x_img = F.relu(self.dec_img_fc2(dec_x_img))\n",
    "        \n",
    "        return dec_x_img, dec_x_txt\n",
    "\n",
    "    def forward(self, x_img, x_txt):\n",
    "        mu, logvar = self.encode(x_img, x_txt)\n",
    "        mu = mu.squeeze()\n",
    "        logvar = logvar.squeeze()\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        y_misogynous = self.subtask_misogynous(z)\n",
    "        y_shaming = self.subtask_shaming(z)\n",
    "        y_stereotype = self.subtask_stereotype(z)\n",
    "        y_objectification = self.subtask_objectification(z)\n",
    "        y_violence = self.subtask_violence(z)\n",
    "        \n",
    "        y_pred = dict()\n",
    "        y_pred[\"misogynous\"] = y_misogynous\n",
    "        y_pred[\"shaming\"] = y_shaming\n",
    "        y_pred[\"stereotype\"] = y_stereotype\n",
    "        y_pred[\"objectification\"] = y_objectification\n",
    "        y_pred[\"violence\"] = y_violence\n",
    "        \n",
    "        dec_x_img, dec_x_txt = self.decode(z.view(-1, self.zsize))\n",
    "        \n",
    "        return dec_x_img, dec_x_txt, mu, logvar, y_pred\n",
    "\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x_img, recon_x_txt, x_img, x_txt, mu, logvar):\n",
    "    BCE_img = torch.mean((recon_x_img - x_img)**2)\n",
    "    BCE_txt = torch.mean((recon_x_txt - x_txt)**2)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.mean(torch.mean(1 + logvar - mu.pow(2) - logvar.exp(), 1))\n",
    "    return BCE_img, BCE_txt, KLD * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"VAE_result.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    name_dict = dict()\n",
    "    name_dict[\"misogynous\"] = 0\n",
    "    name_dict[\"shaming\"] = 1\n",
    "    name_dict[\"stereotype\"] = 2\n",
    "    name_dict[\"objectification\"] = 3\n",
    "    name_dict[\"violence\"] = 4\n",
    "    \n",
    "    #batch_size = 32\n",
    "    z_size = 512\n",
    "#     z_size = 1024\n",
    "    vae = VAE(z_size)\n",
    "    vae.cuda()\n",
    "    vae.train()\n",
    "    vae.weight_init(mean=0, std=0.02)\n",
    "\n",
    "    lr = 0.0001\n",
    "\n",
    "    vae_optimizer = optim.Adam(vae.parameters(), lr=lr, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion.to(device)\n",
    " \n",
    "    train_epoch = 30\n",
    "\n",
    "    \n",
    "    dataloader = train_iterator\n",
    "    \n",
    "    f1_max = 0\n",
    "    max_acc = 0\n",
    "    \n",
    "    for epoch in range(train_epoch):\n",
    "        vae.train()\n",
    "\n",
    "        rec_txt_loss = 0\n",
    "        rec_img_loss = 0\n",
    "        kl_loss = 0\n",
    "        subtask_misogynous_loss = 0\n",
    "        subtask_shaming_loss = 0\n",
    "        subtask_stereotype_loss = 0\n",
    "        subtask_objectification_loss = 0\n",
    "        subtask_violence_loss = 0\n",
    "\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        if (epoch + 1) % 8 == 0:\n",
    "            vae_optimizer.param_groups[0]['lr'] /= 4\n",
    "#             print(\"learning rate change!\")\n",
    "            f.write(\"learning rate change! The learning rate is %1.4f now\\n\" % (lr))\n",
    "\n",
    "#         i = 0\n",
    "        acc = 0\n",
    "        num = 0\n",
    "        for i, data in tqdm(enumerate(dataloader, 0), desc='iterations'):\n",
    "        #for x in batches:\n",
    "            vae.train()\n",
    "            \n",
    "            #inputs, classes = data\n",
    "            img_inputs = data['meme']\n",
    "            img_inputs = img_inputs.to(device)\n",
    "\n",
    "            txt_inputs = data[\"text\"]\n",
    "            txt_inputs = txt_inputs.to(device)\n",
    "            \n",
    "            classes = data['labels']\n",
    "            \n",
    "            # multi-task labels\n",
    "            classes_misogynous = classes[:, 0]\n",
    "            classes_shaming = classes[:, 1]\n",
    "            classes_stereotype = classes[:, 2]\n",
    "            classes_objectification = classes[:, 3]\n",
    "            classes_violence = classes[:, 4]\n",
    "            \n",
    "            img_inputs, txt_inputs, classes_misogynous = Variable(img_inputs), Variable(txt_inputs), Variable(classes_misogynous)\n",
    "            classes_shaming = Variable(classes_shaming)\n",
    "            classes_stereotype = Variable(classes_stereotype)\n",
    "            classes_objectification = Variable(classes_stereotype)\n",
    "            classes_violence = Variable(classes_violence)\n",
    "        \n",
    "            img_inputs = img_inputs.to(device)\n",
    "            txt_inputs = txt_inputs.to(device)\n",
    "            classes_misogynous = classes_misogynous.to(device)\n",
    "            classes_shaming = classes_shaming.to(device)\n",
    "            classes_stereotype = classes_stereotype.to(device)\n",
    "            classes_objectification = classes_objectification.to(device)\n",
    "            classes_violence = classes_violence.to(device)\n",
    "            \n",
    "            vae.zero_grad()\n",
    "#             rec, mu, logvar = vae(x)\n",
    "            rec_img, rec_txt, mu, logvar, y_pred = vae(img_inputs, txt_inputs)\n",
    "\n",
    "            loss_re_img, loss_re_txt, loss_kl = loss_function(rec_img, rec_txt, img_inputs, txt_inputs, mu, logvar)\n",
    "            loss_subtask_misogynous = criterion(y_pred[\"misogynous\"], classes_misogynous)\n",
    "            loss_subtask_shaming = criterion(y_pred[\"shaming\"], classes_shaming)\n",
    "            loss_subtask_stereotype = criterion(y_pred[\"stereotype\"], classes_stereotype)\n",
    "            loss_subtask_objectification = criterion(y_pred[\"objectification\"], classes_objectification)\n",
    "            loss_subtask_violence = criterion(y_pred[\"violence\"], classes_violence)\n",
    "            \n",
    "            (loss_re_img + loss_re_txt + loss_kl + loss_subtask_misogynous \\\n",
    "             + loss_subtask_shaming + loss_subtask_stereotype + loss_subtask_objectification\\\n",
    "             + loss_subtask_violence).backward()\n",
    "            \n",
    "            vae_optimizer.step()\n",
    "            rec_img_loss += loss_re_img.item()\n",
    "            rec_txt_loss += loss_re_txt.item()\n",
    "            \n",
    "            kl_loss += loss_kl.item()\n",
    "            subtask_misogynous_loss += loss_subtask_misogynous.item()\n",
    "            subtask_shaming_loss += loss_subtask_shaming.item()\n",
    "            subtask_stereotype_loss += loss_subtask_stereotype.item()\n",
    "            subtask_objectification_loss += loss_subtask_objectification.item()\n",
    "            subtask_violence_loss += loss_subtask_violence.item()\n",
    "            \n",
    "            # Calculate batch accuracy\n",
    "            _, top_pred = y_pred[\"misogynous\"].topk(1, 1)\n",
    "            y = classes_misogynous.cpu()\n",
    "            batch_size = y.shape[0]\n",
    "            top_pred = top_pred.cpu().view(batch_size)\n",
    "            acc += sum(top_pred == y).item()\n",
    "            num += batch_size\n",
    "\n",
    "            #############################################\n",
    "\n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "\n",
    "            # report losses and save samples each 60 iterations\n",
    "            m = len(dataloader)\n",
    "            i += 1\n",
    "            if i % m == 0:\n",
    "                rec_txt_loss /= m\n",
    "                rec_img_loss /= m\n",
    "                kl_loss /= m\n",
    "                subtask_misogynous_loss /= m\n",
    "                subtask_shaming_loss /= m\n",
    "                subtask_stereotype_loss /= m\n",
    "                subtask_objectification_loss /= m\n",
    "                subtask_violence_loss /= m\n",
    "                \n",
    "#                 print('\\n[%d/%d] - ptime: %.2f, rec img loss: %.9f, rec txt loss: %.9f, KL loss: %.9f, misogynous loss: %.9f, shaming loss: %.9f, stereotype loss: %.9f, objectification loss: %.9f, violence loss: %.9f' % (\n",
    "#                     (epoch + 1), train_epoch, per_epoch_ptime, rec_img_loss, rec_txt_loss, kl_loss, subtask_misogynous_loss, subtask_shaming_loss, subtask_stereotype_loss, subtask_objectification_loss, subtask_violence_loss))\n",
    "\n",
    "                f.write('\\n[%d/%d] - ptime: %.2f, rec img loss: %.9f, rec txt loss: %.9f, KL loss: %.9f, misogynous loss: %.9f, shaming loss: %.9f, stereotype loss: %.9f, objectification loss: %.9f, violence loss: %.9f\\n' % (\n",
    "                    (epoch + 1), train_epoch, per_epoch_ptime, rec_img_loss, rec_txt_loss, kl_loss, subtask_misogynous_loss, subtask_shaming_loss, subtask_stereotype_loss, subtask_objectification_loss, subtask_violence_loss))\n",
    "                rec_txt_loss = 0\n",
    "                rec_img_loss = 0\n",
    "                kl_loss = 0\n",
    "                with torch.no_grad():\n",
    "#                     test_loss, test_acc, test_accuracy, test_f1, test_recall, test_precision = evaluate(vae, valid_iterator, criterion, device, \"misogynous\")\n",
    "                    test_loss, test_acc, test_accuracy, test_f1, test_recall, test_precision = evaluate(vae, valid_iterator, criterion, device)\n",
    "                    f.write(f'Test subtask misogynous Loss: {test_loss[\"misogynous\"]:.3f} | Test Acc @1: {test_acc[\"misogynous\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask misogynous accuracy: {test_accuracy[\"misogynous\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask misogynous f1: {test_f1[\"misogynous\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask misogynous recall: {test_recall[\"misogynous\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask misogynous precision: {test_precision[\"misogynous\"]*100:6.2f}%\\n')\n",
    "                    \n",
    "#                     test_loss, test_acc, test_accuracy, test_f1, test_recall, test_precision = evaluate(vae, trial_iterator, criterion, device, \"shaming\")\n",
    "                    f.write(f'Test subtask shaming Loss: {test_loss[\"shaming\"]:.3f} | Test Acc @1: {test_acc[\"shaming\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask shaming accuracy: {test_accuracy[\"shaming\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask shaming f1: {test_f1[\"shaming\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask shaming recall: {test_recall[\"shaming\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask shaming precision: {test_precision[\"shaming\"]*100:6.2f}%\\n')\n",
    "                    \n",
    "#                     test_loss, test_acc, test_accuracy, test_f1, test_recall, test_precision = evaluate(vae, trial_iterator, criterion, device, \"stereotype\")\n",
    "                    f.write(f'Test subtask stereotype Loss: {test_loss[\"stereotype\"]:.3f} | Test Acc @1: {test_acc[\"stereotype\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask stereotype accuracy: {test_accuracy[\"stereotype\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask stereotype f1: {test_f1[\"stereotype\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask stereotype recall: {test_recall[\"stereotype\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask stereotype precision: {test_precision[\"stereotype\"]*100:6.2f}%\\n')\n",
    "                    \n",
    "#                     test_loss, test_acc, test_accuracy, test_f1, test_recall, test_precision = evaluate(vae, trial_iterator, criterion, device, \"objectification\")\n",
    "                    f.write(f'Test subtask objectification Loss: {test_loss[\"objectification\"]:.3f} | Test Acc @1: {test_acc[\"objectification\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask objectification accuracy: {test_accuracy[\"objectification\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask objectification f1: {test_f1[\"objectification\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask objectification recall: {test_recall[\"objectification\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask objectification precision: {test_precision[\"objectification\"]*100:6.2f}%\\n')\n",
    "                    \n",
    "#                     test_loss, test_acc, test_accuracy, test_f1, test_recall, test_precision = evaluate(vae, trial_iterator, criterion, device, \"violence\")\n",
    "                    f.write(f'Test subtask violence Loss: {test_loss[\"violence\"]:.3f} | Test Acc @1: {test_acc[\"violence\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask violence accuracy: {test_accuracy[\"violence\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask violence f1: {test_f1[\"violence\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask violence recall: {test_recall[\"violence\"]*100:6.2f}%\\n')\n",
    "                    f.write(f'Test subtask violence precision: {test_precision[\"violence\"]*100:6.2f}%\\n')\n",
    "                    \n",
    "                    acc /= num\n",
    "                    print(f'num_correct: {acc}\\n')\n",
    "                    print(f'total_num: {num}\\n')\n",
    "                    f.write(f'Training accuracy: {acc*100:6.2f}%\\n')\n",
    "                    \n",
    "                    if test_f1[\"misogynous\"]*100 >= f1_max:\n",
    "                        \n",
    "                        torch.save(vae.state_dict(), \"VAEmodel-epoch-%d.pkl\" % (epoch+1))\n",
    "                        f.write(\"Epoch [%d/%d]: test f1 on misogynous improves, saving training results\\n\" % (epoch+1, train_epoch))\n",
    "                        f1_max = test_f1[\"misogynous\"]*100\n",
    "\n",
    "        f.flush()\n",
    "\n",
    "    f.write(\"Training finish!... save training results\\n\")\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    with torch.no_grad():\n",
    "        batch_size = y.shape[0]\n",
    "        _, top_pred = y_pred.topk(1, 1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
    "        acc_1 = correct_1 / batch_size\n",
    "    \n",
    "    top_pred = top_pred.cpu().view(batch_size)\n",
    "    y = y.cpu()\n",
    "    \n",
    "    accuracy = accuracy_score(y, top_pred)\n",
    "    #print(\"accuracy: {}\".format(accuracy))\n",
    "\n",
    "    f1 = f1_score(y, top_pred)\n",
    "#     print(top_pred)\n",
    "    #print(\"f1: {}\".format(f1))\n",
    "\n",
    "    recall = recall_score(y, top_pred)\n",
    "    #print(\"recall: {}\".format(recall))\n",
    "\n",
    "    precision = precision_score(y, top_pred)\n",
    "    #print(\"precision: {}\".format(precision))\n",
    "\n",
    "    cm = confusion_matrix(y, top_pred)\n",
    "    #print(\"cm: {}\".format(cm))\n",
    "    return acc_1, accuracy, f1, recall, precision, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device, subtask_name=\"misogynous\"):\n",
    "    \n",
    "    epoch_loss = dict()\n",
    "    epoch_loss[\"misogynous\"] = 0\n",
    "    epoch_loss[\"shaming\"] = 0\n",
    "    epoch_loss[\"stereotype\"] = 0\n",
    "    epoch_loss[\"objectification\"] = 0\n",
    "    epoch_loss[\"violence\"] = 0\n",
    "    \n",
    "    epoch_acc = dict()\n",
    "    epoch_acc[\"misogynous\"] = 0\n",
    "    epoch_acc[\"shaming\"] = 0\n",
    "    epoch_acc[\"stereotype\"] = 0\n",
    "    epoch_acc[\"objectification\"] = 0\n",
    "    epoch_acc[\"violence\"] = 0\n",
    "    \n",
    "    epoch_accuracy = dict()\n",
    "    epoch_accuracy[\"misogynous\"] = 0\n",
    "    epoch_accuracy[\"shaming\"] = 0\n",
    "    epoch_accuracy[\"stereotype\"] = 0\n",
    "    epoch_accuracy[\"objectification\"] = 0\n",
    "    epoch_accuracy[\"violence\"] = 0\n",
    "    \n",
    "    epoch_f1 = dict()\n",
    "    epoch_f1[\"misogynous\"] = 0\n",
    "    epoch_f1[\"shaming\"] = 0\n",
    "    epoch_f1[\"stereotype\"] = 0\n",
    "    epoch_f1[\"objectification\"] = 0\n",
    "    epoch_f1[\"violence\"] = 0\n",
    "    \n",
    "    epoch_recall = dict()\n",
    "    epoch_recall[\"misogynous\"] = 0\n",
    "    epoch_recall[\"shaming\"] = 0\n",
    "    epoch_recall[\"stereotype\"] = 0\n",
    "    epoch_recall[\"objectification\"] = 0\n",
    "    epoch_recall[\"violence\"] = 0\n",
    "    \n",
    "    epoch_precision = dict()\n",
    "    epoch_precision[\"misogynous\"] = 0\n",
    "    epoch_precision[\"shaming\"] = 0\n",
    "    epoch_precision[\"stereotype\"] = 0\n",
    "    epoch_precision[\"objectification\"] = 0\n",
    "    epoch_precision[\"violence\"] = 0\n",
    "    \n",
    "    epoch_cm = dict()\n",
    "    epoch_cm[\"misogynous\"] = 0\n",
    "    epoch_cm[\"shaming\"] = 0\n",
    "    epoch_cm[\"stereotype\"] = 0\n",
    "    epoch_cm[\"objectification\"] = 0\n",
    "    epoch_cm[\"violence\"] = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    name_dict = dict()\n",
    "    name_dict[\"misogynous\"] = 0\n",
    "    name_dict[\"shaming\"] = 1\n",
    "    name_dict[\"stereotype\"] = 2\n",
    "    name_dict[\"objectification\"] = 3\n",
    "    name_dict[\"violence\"] = 4\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        #for (x, y) in iterator:\n",
    "        for i, data in tqdm(enumerate(iterator, 0), desc='iterations'):\n",
    "\n",
    "            x_img = data['meme']\n",
    "            x_img = x_img.to(device)\n",
    "            \n",
    "            x_txt = data['text']\n",
    "            x_txt = x_txt.to(device)\n",
    "            \n",
    "            \n",
    "            y = data['labels']\n",
    "            \n",
    "            x_img, x_txt = x_img.to(device), x_txt.to(device)\n",
    "\n",
    "            _, _, _, _, y_pred = model(x_img, x_txt)\n",
    "            \n",
    "\n",
    "            \n",
    "            for subtask_name, subtask_index in name_dict.items():\n",
    "                subtask_y = y[:, subtask_index]\n",
    "                subtask_y = subtask_y.to(device)\n",
    "                loss = criterion(y_pred[subtask_name], subtask_y)\n",
    "                acc, accuracy, f1, recall, precision, cm = calculate_accuracy(y_pred[subtask_name], subtask_y)\n",
    "                \n",
    "                epoch_loss[subtask_name] += loss.item()\n",
    "                epoch_acc[subtask_name] += acc.item()\n",
    "                epoch_accuracy[subtask_name] += accuracy.item()\n",
    "                epoch_f1[subtask_name] += f1.item()\n",
    "                epoch_recall[subtask_name] += recall.item()\n",
    "                epoch_precision[subtask_name] += precision.item()\n",
    "                # epoch_cm += cm.item()\n",
    "                \n",
    "                \n",
    "    for subtask_name, subtask_index in name_dict.items():\n",
    "        epoch_loss[subtask_name] /= len(iterator)\n",
    "        epoch_acc[subtask_name] /= len(iterator)\n",
    "        epoch_accuracy[subtask_name] /= len(iterator)\n",
    "        epoch_f1[subtask_name] /= len(iterator)\n",
    "        epoch_recall[subtask_name] /= len(iterator)\n",
    "        epoch_precision[subtask_name] /= len(iterator)\n",
    "                \n",
    "        \n",
    "    return epoch_loss, epoch_acc, epoch_accuracy, epoch_f1, epoch_recall, epoch_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5351ef14e6e54c2f8668c67fa0c2f3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='iterations', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee40f56be5c842e0accff6e674e19522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='iterations', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "num_correct: 0.7284444444444444\n",
      "\n",
      "total_num: 9000\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8b71a5069446f9b2d718e32584a450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='iterations', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vae = main()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.to(device)\n",
    "test_loss, test_acc, test_accuracy, test_f1, test_recall, test_precision = evaluate(vae, trial_iterator, criterion, device, \"misogynous\")\n",
    "\n",
    "f.write(f'Trial subtask misogynous Loss: {test_loss:.3f} | Test Acc @1: {test_acc*100:6.2f}%\\n')\n",
    "f.write(f'Trial subtask misogynous accuracy: {test_accuracy*100:6.2f}%\\n')\n",
    "f.write(f'Trial subtask misogynous f1: {test_f1*100:6.2f}%\\n')\n",
    "f.write(f'Trial subtask misogynous recall: {test_recall*100:6.2f}%\\n')\n",
    "f.write(f'Trial subtask misogynous precision: {test_precision*100:6.2f}%\\n')\n",
    "\n",
    "test_loss, test_acc, test_accuracy, test_f1, test_recall, test_precision = evaluate(vae, trial_iterator, criterion, device, \"shaming\")\n",
    "\n",
    "f.write(f'Trial subtask shaming Loss: {test_loss:.3f} | Test Acc @1: {test_acc*100:6.2f}%\\n')\n",
    "f.write(f'Trial subtask shaming accuracy: {test_accuracy*100:6.2f}%\\n')\n",
    "f.write(f'Trial subtask shaming f1: {test_f1*100:6.2f}%\\n')\n",
    "f.write(f'Trial subtask shaming recall: {test_recall*100:6.2f}%\\n')\n",
    "f.write(f'Trial subtask shaming precision: {test_precision*100:6.2f}%\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, iterator, device):\n",
    "    \n",
    "    name_dict = dict()\n",
    "    name_dict[\"misogynous\"] = 0\n",
    "    name_dict[\"shaming\"] = 1\n",
    "    name_dict[\"stereotype\"] = 2\n",
    "    name_dict[\"objectification\"] = 3\n",
    "    name_dict[\"violence\"] = 4\n",
    "    \n",
    "    y_test = dict()\n",
    "    y_test[\"misogynous\"] = []\n",
    "    y_test[\"shaming\"] = []\n",
    "    y_test[\"stereotype\"] = []\n",
    "    y_test[\"objectification\"] = []\n",
    "    y_test[\"violence\"] = []\n",
    "    \n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for i, data in tqdm(enumerate(iterator, 0), desc='iterations'):\n",
    "\n",
    "            x_img = data['meme']\n",
    "            x_img = x_img.to(device)\n",
    "            \n",
    "            x_txt = data['text']\n",
    "            \n",
    "            x_img, x_txt = x_img.to(device), x_txt.to(device)\n",
    "\n",
    "            _, _, _, _, y_pred = model(x_img, x_txt)\n",
    "            \n",
    "            \n",
    "            for subtask_name, subtask_index in name_dict.items():\n",
    "                subtask_y = y_pred[subtask_name].cpu()\n",
    "                for dp in subtask_y:\n",
    "                    if dp[0] >= dp[1]:\n",
    "                        y_test[subtask_name].append(0)\n",
    "                    else:\n",
    "                        y_test[subtask_name].append(1)\n",
    "        \n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_VAE = VAE(512)\n",
    "best_VAE.load_state_dict(torch.load(\"VAEmodel-6.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c09fef636dd46349eb8ba54cc1773e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='iterations', max=1.0, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = test(best_VAE, test_iterator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[\"misogynous\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = test_df.copy()\n",
    "\n",
    "prediction_df[\"misogynous\"] = y_test[\"misogynous\"]\n",
    "prediction_df[\"shaming\"] = y_test[\"shaming\"]\n",
    "prediction_df[\"stereotype\"] = y_test[\"stereotype\"]\n",
    "prediction_df[\"objectification\"] = y_test[\"objectification\"]\n",
    "prediction_df[\"violence\"] = y_test[\"violence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>shaming</th>\n",
       "      <th>stereotype</th>\n",
       "      <th>objectification</th>\n",
       "      <th>violence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15236.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15805.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16254.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16191.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15952.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>15591.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>15049.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>15363.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>15199.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>15853.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name  misogynous  shaming  stereotype  objectification  violence\n",
       "0    15236.jpg           1        0           0                0         0\n",
       "1    15805.jpg           1        0           1                1         0\n",
       "2    16254.jpg           1        0           0                0         0\n",
       "3    16191.jpg           1        0           0                0         0\n",
       "4    15952.jpg           1        0           0                0         0\n",
       "..         ...         ...      ...         ...              ...       ...\n",
       "995  15591.jpg           1        0           1                1         0\n",
       "996  15049.jpg           1        0           0                0         0\n",
       "997  15363.jpg           1        0           0                0         0\n",
       "998  15199.jpg           1        0           1                1         0\n",
       "999  15853.jpg           0        0           0                0         0\n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = prediction_df.drop('Text Transcription', 1)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
